{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panchambanerjee/llm_experiments/blob/main/OpenAIChatExperiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a13ddc8",
      "metadata": {
        "id": "0a13ddc8"
      },
      "source": [
        "# OpenAI Chat Experiment Example"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "623f0cfe",
      "metadata": {
        "id": "623f0cfe"
      },
      "source": [
        "## Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "885dabeb",
      "metadata": {
        "id": "885dabeb"
      },
      "outputs": [],
      "source": [
        "# !pip install --quiet --force-reinstall prompttools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eac35f8",
      "metadata": {
        "id": "2eac35f8"
      },
      "source": [
        "## Setup imports and API keys"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5edba05a",
      "metadata": {
        "id": "5edba05a"
      },
      "source": [
        "First, we'll need to set our API keys. If we are in DEBUG mode, we don't need to use a real OpenAI key, so for now we'll set them to empty strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed4e635e",
      "metadata": {
        "id": "ed4e635e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['DEBUG']=\"1\"  # Set this to \"\" to call OpenAI's API\n",
        "os.environ['OPENAI_API_KEY'] = \"\"  # Insert your key here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842f1e47",
      "metadata": {
        "id": "842f1e47"
      },
      "source": [
        "Then we'll import the relevant `prompttools` modules to setup our experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beaa70a1",
      "metadata": {
        "id": "beaa70a1"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List\n",
        "from prompttools.experiment import OpenAIChatExperiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "622dea9a",
      "metadata": {
        "id": "622dea9a"
      },
      "source": [
        "## Run an experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3babfe5a",
      "metadata": {
        "id": "3babfe5a"
      },
      "source": [
        "Next, we create our test inputs. We can iterate over models, inputs, and configurations like temperature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9114cfbf",
      "metadata": {
        "id": "9114cfbf"
      },
      "outputs": [],
      "source": [
        "models = [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-0613\"]\n",
        "messages = [\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Who was the first president?\"},\n",
        "    ]\n",
        "]\n",
        "temperatures = [0.0, 1.0]\n",
        "# You can add more parameters that you'd like to test here.\n",
        "\n",
        "experiment = OpenAIChatExperiment(models, messages, temperature=temperatures)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3fa5450",
      "metadata": {
        "id": "f3fa5450"
      },
      "source": [
        "We can then run the experiment to get results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b33130",
      "metadata": {
        "id": "83b33130"
      },
      "outputs": [],
      "source": [
        "experiment.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "266c13eb",
      "metadata": {
        "id": "266c13eb"
      },
      "source": [
        "## Evaluate the model response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bebb8023",
      "metadata": {
        "id": "bebb8023"
      },
      "source": [
        "To evaluate the results, we'll define an eval function. We can use semantic distance to check if the model's response is similar to our expected output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ddbb951",
      "metadata": {
        "id": "8ddbb951"
      },
      "outputs": [],
      "source": [
        "from prompttools.utils import similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e80dfeec",
      "metadata": {
        "scrolled": true,
        "id": "e80dfeec"
      },
      "outputs": [],
      "source": [
        "experiment.evaluate(\"similar_to_expected\", similarity.evaluate, expected=\"George Washington\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "974d6065",
      "metadata": {
        "id": "974d6065"
      },
      "source": [
        "Finally, we can visualize the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d09c18e",
      "metadata": {
        "scrolled": true,
        "id": "4d09c18e",
        "outputId": "2b6ede9c-9abe-418c-88e2-e3f900a623b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>messages</th>\n",
              "      <th>response(s)</th>\n",
              "      <th>latency</th>\n",
              "      <th>similar_to_expected</th>\n",
              "      <th>model</th>\n",
              "      <th>temperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]</td>\n",
              "      <td>George Washington</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]</td>\n",
              "      <td>George Washington</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]</td>\n",
              "      <td>George Washington</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]</td>\n",
              "      <td>George Washington</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                       messages  \\\n",
              "0  [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]   \n",
              "1  [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]   \n",
              "2  [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]   \n",
              "3  [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Who was the first president?'}]   \n",
              "\n",
              "         response(s)   latency  similar_to_expected               model  \\\n",
              "0  George Washington  0.000004  0.0                  gpt-3.5-turbo        \n",
              "1  George Washington  0.000003  0.0                  gpt-3.5-turbo        \n",
              "2  George Washington  0.000002  0.0                  gpt-3.5-turbo-0613   \n",
              "3  George Washington  0.000002  0.0                  gpt-3.5-turbo-0613   \n",
              "\n",
              "   temperature  \n",
              "0  0.0          \n",
              "1  1.0          \n",
              "2  0.0          \n",
              "3  1.0          "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "experiment.visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0007a1f",
      "metadata": {
        "id": "d0007a1f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}